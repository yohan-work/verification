import os

# ==========================================
# [Phase 2 ì‹¤ìŠµ] ë¡œì»¬ RAG êµ¬í˜„í•˜ê¸°
# ==========================================
#
# "ë¬¸ì„œ ì„ë² ë”© -> ì €ì¥ -> ê²€ìƒ‰" ê³¼ì •ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.
#
# [í•„ìˆ˜ ì„¤ì¹˜ ë¼ì´ë¸ŒëŸ¬ë¦¬]
# í„°ë¯¸ë„ì—ì„œ ì•„ë˜ ëª…ë ¹ì–´ë¥¼ ì‹¤í–‰í•´ì£¼ì„¸ìš”:
# pip install langchain-community langchain-huggingface chromadb sentence-transformers
#
# ==========================================

try:
    from langchain_huggingface import HuggingFaceEmbeddings
    from langchain_community.vectorstores import Chroma
    from langchain_core.documents import Document
except ImportError as e:
    print(f"ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. (Error: {e})")
    print("í„°ë¯¸ë„ì— ë‹¤ìŒì„ ì…ë ¥í•˜ì„¸ìš”:")
    print("pip install langchain-community langchain-huggingface chromadb sentence-transformers")
    exit()

def main():
    print("1. ë¡œì»¬ ì„ë² ë”© ëª¨ë¸ ë¡œë”© ì¤‘... (ìµœì´ˆ ì‹¤í–‰ ì‹œ ë‹¤ìš´ë¡œë“œì— ì‹œê°„ì´ ê±¸ë¦½ë‹ˆë‹¤)")
    # í•œêµ­ì–´ ì²˜ë¦¬ì— ê°•ë ¥í•œ ì˜¤í”ˆì†ŒìŠ¤ ëª¨ë¸ ì‚¬ìš© (HuggingFace)
    # CPUì—ì„œë„ ë¬´ë¦¬ ì—†ì´ ëŒì•„ê°€ëŠ” ê²½ëŸ‰ ëª¨ë¸ì…ë‹ˆë‹¤.
    embedding_model = HuggingFaceEmbeddings(
        model_name="jhgan/ko-sroberta-multitask"
    )
    print("ëª¨ë¸ ë¡œë”© ì™„ë£Œ!")

    # ---------------------------------------------------------
    # 2. ê°€ìƒì˜ ì‚¬ë‚´ ë°ì´í„° ì¤€ë¹„ (Document Loading)
    # ì‹¤ì œë¡œëŠ” PDFë‚˜ í…ìŠ¤íŠ¸ íŒŒì¼ì—ì„œ ì½ì–´ì˜¤ëŠ” ë¶€ë¶„ì…ë‹ˆë‹¤.
    # ---------------------------------------------------------
    raw_documents = [
        "AI CoE íŒ€ì€ 2024ë…„ì— ì‹ ì„¤ëœ ì¡°ì§ìœ¼ë¡œ, ì „ì‚¬ AI ë„ì…ì„ ê°€ì†í™”í•˜ëŠ” ì—­í• ì„ ë§¡ìŠµë‹ˆë‹¤.",
        "ìš°ë¦¬ íšŒì‚¬ì˜ í´ë¼ìš°ë“œ ë¹„ìš© ê·œì •ì— ë”°ë¥´ë©´, ì›” 100ë§Œì› ì´ìƒì˜ GPU ì¸ìŠ¤í„´ìŠ¤ ì‚¬ìš©ì€ CTO ìŠ¹ì¸ì´ í•„ìš”í•©ë‹ˆë‹¤.",
        "ì ì‹¬ ì‹ëŒ€ ì§€ì› í•œë„ëŠ” 2025ë…„ë¶€í„° 12,000ì›ìœ¼ë¡œ ì¸ìƒë˜ì—ˆìŠµë‹ˆë‹¤.",
        "AI í”„ë¡œì íŠ¸ í”„ë¡œì„¸ìŠ¤ëŠ” ê¸°íš -> PoC -> ê²€ì¦ -> ë°°í¬ ìˆœì„œë¡œ ì§„í–‰ë©ë‹ˆë‹¤.",
        "ì¬íƒ ê·¼ë¬´ëŠ” ì£¼ 2íšŒ ê°€ëŠ¥í•˜ë©°, íŒ€ì¥ ì „ê²°ë¡œ ìŠ¹ì¸ë©ë‹ˆë‹¤."
    ]
    
    # LangChain Document í˜•ì‹ìœ¼ë¡œ ë³€í™˜
    docs = [Document(page_content=text) for text in raw_documents]
    print(f"ë¬¸ì„œ {len(docs)}ê°œë¥¼ ì¤€ë¹„í–ˆìŠµë‹ˆë‹¤.")

    # ---------------------------------------------------------
    # 3. Vector DB ìƒì„± ë° ì €ì¥ (Indexing)
    # ---------------------------------------------------------
    # ChromaDBë¥¼ ì‚¬ìš©í•˜ì—¬ ë©”ëª¨ë¦¬ì— ë²¡í„° ì €ì¥ì†Œë¥¼ ë§Œë“­ë‹ˆë‹¤.
    print("Vector DBì— ë°ì´í„°ë¥¼ ì €ì¥(Indexing) ì¤‘...")
    vector_store = Chroma.from_documents(
        documents=docs,
        embedding=embedding_model,
        collection_name="company_knowledge"
    )
    print("ì €ì¥ ì™„ë£Œ!")

    # ---------------------------------------------------------
    # 4. ê²€ìƒ‰ í…ŒìŠ¤íŠ¸ (Retrieval)
    # ---------------------------------------------------------
    while True:
        print("\n" + "="*50)
        query = input("ğŸ” ê¶ê¸ˆí•œ ì ì„ ë¬¼ì–´ë³´ì„¸ìš” (ì¢…ë£Œí•˜ë ¤ë©´ 'exit' ì…ë ¥): ")
        
        if query.lower() == 'exit':
            break
            
        print(f"'{query}' ê´€ë ¨ ì •ë³´ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤...")
        
        # ìœ ì‚¬ë„ ê²€ìƒ‰ (Similarity Search)
        # k=2 : ê°€ì¥ ìœ ì‚¬í•œ ë¬¸ì„œ 2ê°œë§Œ ê°€ì ¸ì˜¤ê¸°
        results = vector_store.similarity_search(query, k=2)
        
        if not results:
            print("ê´€ë ¨ ì •ë³´ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
            continue
            
        print("\n[ê²€ìƒ‰ ê²°ê³¼]")
        for i, doc in enumerate(results):
            print(f"{i+1}. {doc.page_content}")
            
        print("\n[Tip] ìœ„ ê²€ìƒ‰ ê²°ê³¼ë¥¼ LLM í”„ë¡¬í”„íŠ¸ì— ë„£ìœ¼ë©´ ë‹µë³€ì´ ì™„ì„±ë©ë‹ˆë‹¤.")

if __name__ == "__main__":
    main()
