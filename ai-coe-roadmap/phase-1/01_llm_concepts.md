# 01. LLM 핵심 개념 및 파라미터 이해

AI 서비스를 개발하기 위해서는 엔진이 되는 LLM(Large Language Model)의 작동 원리와 제어 방법을 이해해야 합니다. 무료 버전의 웹 인터페이스(ChatGPT, Gemini, Claude)에서는 파라미터를 직접 조절하기 어려울 수 있지만, 개념을 이해하면 **프롬프트로 일부 제어가 가능**하거나, 추후 API 사용 시 필수적입니다.

## 1. 주요 파라미터 (Parameters)

LLM은 확률에 기반해 다음 단어를 예측합니다. 이 확률 분포를 조절하는 변수들입니다.

### Temperature (온도)
- **개념**: 모델의 '창의성' 또는 '무작위성'을 조절합니다.
- **범위**: 보통 0.0 ~ 1.0 (일부 모델은 2.0까지)
- **작동 원리**:
    - **낮음 (0.0 ~ 0.3)**: 가장 확률이 높은 단어만 선택. **사실적, 논리적, 정답이 정해진 작업**(코딩, 요약, 데이터 추출)에 적합.
    - **높음 (0.7 ~ 1.0)**: 확률이 낮은 단어도 선택 기회를 줌. **창의적 글쓰기, 아이디어 발상, 시/소설 창작**에 적합.
- **Tip (무료 Web UI)**: "창의적으로 써줘" 또는 "건조하고 사실만 나열해줘"라고 지시하면 내부적으로 유사한 효과를 냅니다.

## Top-P (Nucleus Sampling)
- **개념**: 상위 P% 확률을 가진 단어들 집합 내에서만 다음 단어를 선택합니다.
- **예시**: Top-P가 0.9라면, 상위 90% 확률을 차지하는 단어들만 후보로 두고 나머지는 버립니다.
- **용도**: Temperature와 비슷하지만, 문장의 다양성을 좀 더 안정적으로 확보할 때 씁니다. 보통 Temperature와 둘 중 하나만 조절합니다.

## Hallucination (환각)
- **개념**: 모델이 사실이 아닌 내용을 마치 사실인 것처럼 그럴싸하게 지어내는 현상.
- **원인**: LLM은 '지식'을 검색하는 게 아니라 '문장의 그럴듯한 연결'을 생성하기 때문입니다.
- **대처**:
    - 프롬프트에 "모르면 모른다고 해줘"라고 명시.
    - 참조할 내용(Context)을 제공하고 "위 내용에 기반해서면 답해"라고 제약(Phase 2 RAG의 핵심).

## 2. 토큰 (Token)과 컨텍스트 (Context)

## 토큰 (Token)
- LLM은 텍스트를 '단어'가 아닌 '토큰' 단위로 처리합니다.
- **영어**: 단어 1개 ≈ 1 토큰 (roughly)
- **한국어**: 단어 1개 ≈ 2~3 토큰 (음절 단위 분리가 많아 더 비쌉니다.)
- **중요성**: API 사용 시 비용은 **토큰 단위**로 청구됩니다.

## Context Window (문맥 창)
- **개념**: 모델이 한 번의 대화에서 기억하고 처리할 수 있는 최대 토큰 길이.
- **한계**: 입력(질문) + 출력(답변)의 합이 이 윈도우를 넘어가면, 모델은 **가장 오래된 대화 내용부터 잊어버립니다.**
- **무료 버전**: 보통 유료 버전에 비해 Context Window가 작습니다. 긴 문서를 넣으면 앞 내용을 잘라먹을 수 있습니다.

---

# Phase 1 실습 과제: 파라미터 체감하기
API가 없다면, 프롬프트로 페르소나를 부여하여 파라미터 효과를 흉내내 봅니다.

1. **Low Temperature 효과 내기**
    - 프롬프트: *"너는 엄격한 논리학자야. 어떠한 미사여구도 빼고, 2+2=5가 될 수 없는 이유를 건조하고 사실적으로만 3문장으로 설명해."*
2. **High Temperature 효과 내기**
    - 프롬프트: *"너는 초현실주의 시인이야. 2+2=5가 되는 몽환적인 세상을 상상해서 3문장의 시로 표현해줘."*
